{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "\n",
        "def get_train_valid_samplers(train_dataset, validation_split=0.3, shuffle_dataset=True, random_seed=42):\n",
        "    dataset_size = len(train_dataset)\n",
        "    indices = list(range(dataset_size))\n",
        "    split = int(np.floor(validation_split * dataset_size))\n",
        "\n",
        "    if shuffle_dataset:\n",
        "       np.random.seed(random_seed)\n",
        "       np.random.shuffle(indices)\n",
        "\n",
        "    train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "    train_sampler = SubsetRandomSampler(train_indices)\n",
        "    valid_sampler = SubsetRandomSampler(val_indices)\n",
        "    return train_sampler, valid_sampler\n",
        "\n",
        "train_sampler, valid_sampler = get_train_valid_samplers(train_dataset)"
      ],
      "metadata": {
        "id": "EQlHVHdikHFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fm4gt526RhC"
      },
      "source": [
        "### train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Вход в kaggle по Api tokeny, в настройках аккаунта kaggle\n",
        "\n",
        "import kagglehub\n",
        "kagglehub.login()"
      ],
      "metadata": {
        "id": "Eq8XDOIDno4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Скачиваем датасет, а так же передаём в него путь к датасету\n",
        "\n",
        "ml_intensive_yandex_academy_spring_2025_path = kagglehub.competition_download('ml-intensive-yandex-academy-spring-2025')\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "id": "tMXy_oYwnnbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "K_2Q081pV6So"
      },
      "outputs": [],
      "source": [
        "# !pip uninstall -y tensorflow && pip install tensorflow-cpu # пусть будет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvvmKGlN5ivI"
      },
      "outputs": [],
      "source": [
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import multiprocessing as mp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzUiCLu-1uLy"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def train_fn(rank, model, train_loader, valid_loader, optimizer, criterion, num_epochs, device, path_of_model):\n",
        "    # функция обучения\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "    train_F1 = []\n",
        "    Val_F1 = []\n",
        "\n",
        "    xm.master_print('-'*55)\n",
        "    xm.master_print(f'- initialization | TPU cores = {xm.xrt_world_size()}\\t\\t')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        xm.master_print('-'*55)\n",
        "        xm.master_print('EPOCH {}/{}'.format(epoch + 1, num_epochs))\n",
        "\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "\n",
        "        # TRAIN\n",
        "\n",
        "        for bathc_inx, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            xm.optimizer_step(optimizer, barrier=True)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "        train_accuracy = accuracy_score(y_true, y_pred)\n",
        "        tr_f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        train_F1.append(tr_f1)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "\n",
        "        # VALID\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in valid_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                y_true.extend(labels.cpu().numpy())\n",
        "                y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "        val_loss_epoch = val_loss / len(valid_loader)\n",
        "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "        val_accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "        val_losses.append(val_loss_epoch)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "        Val_F1.append(f1)\n",
        "\n",
        "        xm.master_print(f'Core: {rank}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss_epoch:.4f}, Train Acc: {train_accuracy*100:.2f}%, Val Acc: {val_accuracy*100:.2f}%, Train F1: {tr_f1:.4f}, Val F1: {f1:.4f}')\n",
        "\n",
        "    # сохранение результатов(для графиков) и модели\n",
        "    results = {\n",
        "                'train_losses': train_losses,\n",
        "                'val_losses': val_losses,\n",
        "                'train_accuracies': train_accuracies,\n",
        "                'val_accuracies': val_accuracies,\n",
        "                'train_F1': train_F1,\n",
        "                'Val_F1': Val_F1\n",
        "            }\n",
        "    torch.save(results, f\"results_{rank}.pth\")\n",
        "\n",
        "    if xm.is_master_ordinal():\n",
        "        torch.save(model.state_dict(), path_of_model)\n",
        "\n",
        "def _mp_fn(rank, flags):\n",
        "    xm.rendezvous('checking_out')\n",
        "\n",
        "    device = xm.xla_device()\n",
        "    # ЗДЕСЬ СТАВИТСЯ МОДЕЛЬ\n",
        "    modelь = Model1().to(device)\n",
        "    optimizer = torch.optim.Adamax(modelь.parameters(), lr=flags.lr, weight_decay=1e-5)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "            train_dataset + train_dataset_augm,\n",
        "            batch_size=flags.batch_size,\n",
        "            sampler=train_sampler,\n",
        "            drop_last=True,\n",
        "            num_workers=0\n",
        "        )\n",
        "\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=flags.batch_size,\n",
        "            sampler=valid_sampler,\n",
        "            drop_last=True,\n",
        "            num_workers=0\n",
        "        )\n",
        "\n",
        "    train_fn(rank, modelь, train_loader, valid_loader, optimizer, criterion, flags.epochs, device, flags.path_of_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PA385JgI5iva"
      },
      "outputs": [],
      "source": [
        "# здесь можно изменять пораметры обучения\n",
        "class Flags:\n",
        "    def __init__(self, epochs=2, batch_size=128, lr=0.01, path_of_model='model1.pth'):\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = lr\n",
        "        self.path_of_model = path_of_model\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    FLAGS = Flags()\n",
        "\n",
        "    xmp.spawn(_mp_fn, args=(FLAGS,), start_method='fork')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# для инициализации обученой модели\n",
        "\n",
        "device = xm.xla_device()\n",
        "final_modelь = Model1().to(xm.xla_device())\n",
        "final_modelь.load_state_dict(torch.load('model1.pth', map_location=device))"
      ],
      "metadata": {
        "id": "FF3tVDRWlb4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание словаря после обучения для сбора метрик из файлов с каждого ядра\n",
        "import numpy as np\n",
        "\n",
        "results = {\n",
        "            'train_losses': np.mean(np.array([eval(f\"torch.load('results_{i}.pth', map_location=device)\")['train_losses'] for i in range(7)]), axis=0).tolist(),\n",
        "            'val_losses': np.mean(np.array([eval(f\"torch.load('results_{i}.pth', map_location=device)\")['val_losses'] for i in range(7)]), axis=0).tolist(),\n",
        "            'train_accuracies': np.mean(np.array([eval(f\"torch.load('results_{i}.pth', map_location=device)\")['train_accuracies'] for i in range(7)]), axis=0).tolist(),\n",
        "            'val_accuracies': np.mean(np.array([eval(f\"torch.load('results_{i}.pth', map_location=device)\")['val_accuracies'] for i in range(7)]), axis=0).tolist(),\n",
        "            'train_F1': np.mean(np.array([eval(f\"torch.load('results_{i}.pth', map_location=device)\")['train_F1'] for i in range(7)]), axis=0).tolist(),\n",
        "            'Val_F1': np.mean(np.array([eval(f\"torch.load('results_{i}.pth', map_location=device)\")['Val_F1'] for i in range(7)]), axis=0).tolist()\n",
        "            }\n",
        "\n",
        "results"
      ],
      "metadata": {
        "id": "jmJUD3FkNPur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "def show_loss_accuracy(loss, val_loss, acc, val_acc, tr_f1, val_f1):\n",
        "    clear_output()\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(loss, label='Train Loss')\n",
        "    plt.plot(val_loss, label='Val Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss Curves')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(acc, label='Train Accur')\n",
        "    plt.plot(val_acc, label='Val Accur')\n",
        "    plt.legend()\n",
        "    plt.title('Accuracy')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(tr_f1, label=\"Train F1\")\n",
        "    plt.plot(val_f1, label='Valid F1')\n",
        "    plt.legend()\n",
        "    plt.title('F1')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "6XniVtTXJ3ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCXJu_5mwpLN"
      },
      "outputs": [],
      "source": [
        "show_loss_accuracy(results['train_losses'], results['val_losses'], results['train_accuracies'], results['val_accuracies'], results['train_F1'], results['Val_F1'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "tpu1vmV38",
      "dataSources": [
        {
          "databundleVersionId": 11691206,
          "sourceId": 98102,
          "sourceType": "competition"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 299813,
          "modelInstanceId": 278908,
          "sourceId": 332843,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 30919,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
